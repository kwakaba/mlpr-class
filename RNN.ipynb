{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nandenjin/mlpr-class/blob/use-legacy-torchtext/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2LbyXmJTZVm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b6c00b-624b-480b-8bd3-ecfaa79221df"
      },
      "source": [
        "%pylab inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKWD-JhCTZVu"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtFGIlYVTZVv"
      },
      "source": [
        "import torchtext"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fEw_qcYTZVw"
      },
      "source": [
        "def tokenizer(text):\n",
        "    return text.split()\n",
        "\n",
        "TEXT = torchtext.legacy.data.Field(sequential=True, batch_first=True, tokenize=tokenizer, lower=True)\n",
        "LABEL = torchtext.legacy.data.Field(sequential=False)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XAlSgrCTZVx"
      },
      "source": [
        "train, valid, test = torchtext.legacy.datasets.SST.splits(TEXT, LABEL, root='data')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZysDVUCRTZVx"
      },
      "source": [
        "# To use IMDb, which is a movie review dataset with positive/negative sentiment tags, the following code is used.\n",
        "# （ポジティブ/ネガティブの感情タグ付きの映画のレビューデータセットであるIMDbを用いる場合は以下のコードを用いる．）\n",
        "#\n",
        "# train, test = torchtext.datasets.IMDB.splits(TEXT, LABEL, root='data')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiIZkYPgTZVy"
      },
      "source": [
        "# To use your own dataset, use the following code.\n",
        "# This code assumes that you have train.tsv and test.tsv files in the data/my_text_dataset folder, \n",
        "# which contain tab-delimited pairs of \"text\" and \"label\" for each line.\n",
        "# （自作のデータセットを用いる場合は，以下のコードを用いる．\n",
        "# このコードでは，data/my_text_dataset フォルダに，タブ区切りで「テキスト」と「ラベル」を\n",
        "# 1行に1組ずつ列挙した train.tsv および test.tsv のファイルがあることを想定している．）\n",
        "# \n",
        "# **Note**: In the following code, the text and labels of the batch (i.e., data) are accessed as\n",
        "# data.text and data.label, but when using the TabularDataset class, these should be replaced with\n",
        "# data.Text and data.Label. \n",
        "# As of June 24, 2020, the variable names in torchtext seem to be inconsistent.\n",
        "# If you don't rewrite it, you will get the error `'Batch' object has no attribute 'text'`.\n",
        "# （**注意**：以降のコードでは，バッチ（変数名を data とする）のテキストやラベルを data.text や data.label として\n",
        "# アクセスしているが，TabularDataset クラスを用いる場合には，これを data.Text や data.Label と書き換えること．\n",
        "# 2020年6月24日時点で，torchtextの中で変数名が一貫していないようである．\n",
        "# 書き換えないと `'Batch' object has no attribute 'text'` というエラーが出る．）\n",
        "#\n",
        "# train, test = torchtext.data.TabularDataset.splits(path='./data/my_text_dataset',\n",
        "#                                          train='train.tsv', test='test.tsv', format='tsv',\n",
        "#                                          fields=[('Text', TEXT), ('Label', LABEL)])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpojfoOfTZVz"
      },
      "source": [
        "TEXT.build_vocab(train, max_size=25000)\n",
        "# To use a pre-trained word embedding vector, use the following code.\n",
        "# （事前学習済みの単語埋め込みベクトルを用いる場合は，以下のコードを用いる．）\n",
        "# TEXT.build_vocab(train, vectors=\"glove.6B.100d\")\n",
        "\n",
        "LABEL.build_vocab(train)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "NQ69PWeCTZV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d4ce21-5f0e-45f8-ef79-0184164a20d6"
      },
      "source": [
        "print(LABEL.vocab.stoi.items())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_items([('<unk>', 0), ('positive', 1), ('negative', 2), ('neutral', 3)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kox-xZjMTZV1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b539e97-7952-4756-9a91-ac401091477c"
      },
      "source": [
        "print(list(TEXT.vocab.stoi.items())[:20])\n",
        "print(len(TEXT.vocab))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('<unk>', 0), ('<pad>', 1), ('.', 2), ('the', 3), (',', 4), ('a', 5), ('and', 6), ('of', 7), ('to', 8), ('is', 9), (\"'s\", 10), ('it', 11), ('that', 12), ('in', 13), ('as', 14), ('but', 15), ('film', 16), ('with', 17), ('for', 18), ('this', 19)]\n",
            "16581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27JOx-AKTZV1"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "trainloader, testloader = torchtext.legacy.data.BucketIterator.splits((train, test), batch_size=4, device=device)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md-yz9kpTZV1"
      },
      "source": [
        "dataiter = iter(trainloader)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iFme-EYTZV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76a35572-3935-4e03-e4b4-9e690e17e587"
      },
      "source": [
        "data = dataiter.__next__()\n",
        "x, y = data.text, data.label\n",
        "for x_i in x:\n",
        "    print(' '.join(TEXT.vocab.itos[w] for w in x_i))\n",
        "print([LABEL.vocab.itos[yi] for yi in y])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the picture runs a mere 84 minutes , but it 's no glance . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "it 's a drawling , slobbering , lovable run-on sentence of a film , a southern gothic with the emotional arc of its raw blues soundtrack .\n",
            "topics that could make a sailor blush - but lots of laughs . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "a crude teen-oriented variation on a theme that the playwright craig lucas explored with infinitely more grace and eloquence in his prelude to a kiss . <pad>\n",
            "['positive', 'neutral', 'positive', 'neutral']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64TsbX1yTZV2"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, (hn, cn) = self.lstm(x)\n",
        "        hn = hn.squeeze(0)\n",
        "        return self.fc(hn)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdpeEyvATZV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15209086-665f-4ea2-defe-659a64edef88"
      },
      "source": [
        "from itertools import islice\n",
        "rnn = RNN(len(TEXT.vocab), 100, 30, 3)\n",
        "# If you want to use a pre-trained word embedding vector, insert the following code.\n",
        "# （事前学習済みの単語埋め込みベクトルを用いる場合は，以下のコードを挿入する．）\n",
        "# rnn.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
        "rnn.to(device)\n",
        "optimizer = optim.SGD(rnn.parameters(), lr = 0.01)\n",
        "for epoch in range(10):\n",
        "    sumloss = 0.0\n",
        "    # In an environment with sufficient computing resources, it is better to use all the data.\n",
        "    # （計算資源が十分ある環境では，全てのデータを使う方が良い）\n",
        "    #for data in trainloader:  （計算資源が十分ある環境では，全てのデータを使う方が良い）\n",
        "    for data in islice(trainloader, 250): # Using only 250 batches\n",
        "        x, y = data.text, data.label - 1\n",
        "        optimizer.zero_grad()\n",
        "        a = rnn(x)\n",
        "        loss = F.cross_entropy(a, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        sumloss += loss.item()\n",
        "    print('epoch: {}, loss: {:.4f}'.format(epoch, sumloss))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, loss: 262.0990\n",
            "epoch: 1, loss: 261.7577\n",
            "epoch: 2, loss: 264.9352\n",
            "epoch: 3, loss: 263.5806\n",
            "epoch: 4, loss: 260.6746\n",
            "epoch: 5, loss: 258.7201\n",
            "epoch: 6, loss: 264.9055\n",
            "epoch: 7, loss: 261.0733\n",
            "epoch: 8, loss: 259.9581\n",
            "epoch: 9, loss: 261.9754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmQFOsDNTZV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d8df93-a39f-400c-aaa6-940d25662af0"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        x, y = data.text, data.label - 1\n",
        "        a = rnn(x)\n",
        "        pred_y = torch.argmax(a, dim=1)\n",
        "        correct += (pred_y == y).sum().item()\n",
        "        total += pred_y.size(0)\n",
        "\n",
        "print(correct / total)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4104072398190045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf9AxkjhTZV3"
      },
      "source": [
        "dataiter = iter(testloader)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-90TCI21TZV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb495c2-b8e6-4058-c6e8-137db41820cc"
      },
      "source": [
        "data = dataiter.__next__()\n",
        "x, y = data.text, data.label\n",
        "for x_i in x:\n",
        "    print(' '.join(TEXT.vocab.itos[w] for w in x_i))\n",
        "a = rnn(x)\n",
        "pred_y = torch.argmax(a, dim=1)\n",
        "print([LABEL.vocab.itos[yi + 1] for yi in pred_y])\n",
        "print([LABEL.vocab.itos[yi] for yi in y])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "immediately .\n",
            "no. .\n",
            "<unk> .\n",
            "hopkins .\n",
            "['positive', 'positive', 'positive', 'positive']\n",
            "['neutral', 'negative', 'neutral', 'neutral']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30F33TT0TZV5"
      },
      "source": [
        ""
      ],
      "execution_count": 53,
      "outputs": []
    }
  ]
}