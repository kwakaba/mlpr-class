{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n2LbyXmJTZVm",
    "outputId": "a7b6c00b-624b-480b-8bd3-ecfaa79221df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YKWD-JhCTZVu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dtFGIlYVTZVv"
   },
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torchtext.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3fEw_qcYTZVw"
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwakaba/.pyenv/versions/3.10.5/envs/default2/lib/python3.10/site-packages/torch/utils/data/datapipes/utils/common.py:24: UserWarning: Lambda function is not supported for pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\n",
      "/Users/kwakaba/.pyenv/versions/3.10.5/envs/default2/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/selecting.py:54: UserWarning: Lambda function is not supported for pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\"Lambda function is not supported for pickle, please use \"\n"
     ]
    }
   ],
   "source": [
    "# SST2 is a dataset with positive/negative sentiment labels.\n",
    "# （SST2は、正負の感情ラベルを持つデータセットである。）\n",
    "# Label numbers mean: 0=negative, 1=positive\n",
    "\n",
    "from torchtext.datasets import SST2\n",
    "train = SST2(split='train').map(lambda x: (x[0], str(x[1])))\n",
    "test = SST2(split='dev').map(lambda x: (x[0], str(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following code to use IMDb, which is a movie review dataset with positive/negative sentiment tags.\n",
    "# While SST2 is a stream of (text, label) pairs, IMDb is of (label, text) pairs, so we apply map to align the type of the stream.\n",
    "# See the following site to check the structure of other datasets:\n",
    "# （ポジティブ/ネガティブの感情タグ付きの映画のレビューデータセットであるIMDbを用いる場合は以下のコードを用いる．\n",
    "# 　SST2は(text, label)のペアのストリームですが、IMDbは(label, text)のペアなので、ストリームの型を揃えるために、mapを適用します。\n",
    "# 　他のデータセットの構造を確認したい場合は、以下のサイトを参照してください。）\n",
    "# https://pytorch.org/text/stable/datasets.html\n",
    "\n",
    "# from torchtext.datasets import IMDB\n",
    "# train = IMDB(split='train').map(lambda x: (x[1], x[0]))\n",
    "# test = IMDB(split='test').map(lambda x: (x[1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following code to use AG News, which is a news article dataset with genre tags.\n",
    "# （以下のコードを実行すると、ジャンルタグ付きのニュース記事データセットであるAG Newsが利用できます。）\n",
    "# Labels numbers mean: 1=“World”, 2=“Sports”, 3=“Business”, 4=“Sci/Tech”\n",
    "\n",
    "# from torchtext.datasets import AG_NEWS\n",
    "# train = AG_NEWS(split='train').map(lambda x: (x[1], str(x[0])))\n",
    "# test = AG_NEWS(split='test').map(lambda x: (x[1], str(x[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following code to use your own dataset.\n",
    "# This code assumes that you have train.tsv and test.tsv files in the data/my_text_dataset folder, \n",
    "# which contain tab-delimited pairs of \"text\" and \"label\" for each line.\n",
    "# （自作のデータセットを用いる場合は，以下のコードを用いる．\n",
    "# 　このコードでは，data/my_text_dataset フォルダに，タブ区切りで「テキスト」と「ラベル」を\n",
    "# 　1行に1組ずつ列挙した train.tsv および test.tsv のファイルがあることを想定している．）\n",
    "\n",
    "# import pandas as pd\n",
    "# train = pd.read_table('./data/my_text_dataset/train.tsv', header=None).values\n",
    "# test = pd.read_table('./data/my_text_dataset/test.tsv', header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "token_counter = Counter()\n",
    "label_counter = Counter()\n",
    "for text, label in train:\n",
    "    token_counter.update(tokenize(text))\n",
    "    label_counter[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 27205),\n",
       " (',', 25980),\n",
       " ('a', 21609),\n",
       " ('and', 19920),\n",
       " ('of', 17907),\n",
       " ('.', 12687),\n",
       " ('to', 12538),\n",
       " (\"'s\", 8764),\n",
       " ('is', 8685),\n",
       " ('that', 7759)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'0': 29780, '1': 37569})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import vocab\n",
    "text_vocab = vocab(token_counter, min_freq=2, specials=['<unk>', '<pad>', '<bos>', '<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use a pre-trained word embedding vector, run the following code.\n",
    "# （事前学習済みの単語埋め込みベクトルを用いる場合は，以下のコードを用いる．）\n",
    "\n",
    "# glove = torchtext.vocab.GloVe()\n",
    "# text_vocab = vocab(glove.stoi, specials=['<unk>', '<pad>', '<bos>', '<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vocab.set_default_index(text_vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vocab = torchtext.vocab.vocab(label_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transform = T.Sequential(\n",
    "    T.VocabTransform(text_vocab),\n",
    "    T.Truncate(50-2),\n",
    "    T.AddToken(token=text_vocab['<bos>'], begin=True),\n",
    "    T.AddToken(token=text_vocab['<eos>'], begin=False),\n",
    "    T.ToTensor(padding_value=text_vocab['<pad>'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    texts = text_transform([tokenize(text) for (text, label) in batch])\n",
    "    labels = torch.tensor([label_vocab[label] for (text, label) in batch])\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train, batch_size=4, shuffle=True, collate_fn=collate_batch)\n",
    "testloader = DataLoader(test, batch_size=4, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  4,  5,  6,  7,  8,  9, 10,  3,  1,  1,  1,  1,  1],\n",
      "        [ 2, 11, 12, 13, 14, 15, 16, 17,  3,  1,  1,  1,  1,  1],\n",
      "        [ 2, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,  3],\n",
      "        [ 2, 30, 31, 32, 33, 34,  8, 35, 36,  3,  1,  1,  1,  1]])\n",
      "tensor([0, 0, 1, 0])\n",
      "['<bos>', 'hide', 'new', 'secretions', 'from', 'the', 'parental', 'units', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "0\n",
      "['<bos>', 'contains', 'no', 'wit', ',', 'only', 'labored', 'gags', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "0\n",
      "['<bos>', 'that', 'loves', 'its', 'characters', 'and', 'communicates', 'something', 'rather', 'beautiful', 'about', 'human', 'nature', '<eos>']\n",
      "1\n",
      "['<bos>', 'remains', 'utterly', 'satisfied', 'to', 'remain', 'the', 'same', 'throughout', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "data = trainloader.__iter__().__next__()\n",
    "x, y = data\n",
    "print(x)\n",
    "print(y)\n",
    "for x_i, y_i in zip(x, y):\n",
    "    print(text_vocab.lookup_tokens(list(x_i)))\n",
    "    print(label_vocab.lookup_token(y_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "64TsbX1yTZV2"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        # If you want to use a pre-trained word embedding vector, insert the following code.\n",
    "        # （事前学習済みの単語埋め込みベクトルを用いる場合は，以下のコードを挿入する．）\n",
    "        # self.embedding = nn.Embedding.from_pretrained(glove.vectors, freeze=True)\n",
    "        self.lstm = nn.LSTM(self.embedding.embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, (hn, cn) = self.lstm(x)\n",
    "        hn = hn.squeeze(0)\n",
    "        return self.fc(hn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdpeEyvATZV2",
    "outputId": "15209086-665f-4ea2-defe-659a64edef88",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwakaba/.pyenv/versions/3.10.5/envs/default2/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/combining.py:180: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 174.5874\n",
      "epoch: 1, loss: 173.1876\n",
      "epoch: 2, loss: 172.4343\n",
      "epoch: 3, loss: 170.8540\n",
      "epoch: 4, loss: 167.8444\n",
      "epoch: 5, loss: 163.4136\n",
      "epoch: 6, loss: 157.9567\n",
      "epoch: 7, loss: 152.2603\n",
      "epoch: 8, loss: 147.8479\n",
      "epoch: 9, loss: 140.4318\n",
      "epoch: 10, loss: 132.1370\n",
      "epoch: 11, loss: 120.7141\n",
      "epoch: 12, loss: 112.0275\n",
      "epoch: 13, loss: 99.5499\n",
      "epoch: 14, loss: 88.7921\n",
      "epoch: 15, loss: 82.1006\n",
      "epoch: 16, loss: 73.5971\n",
      "epoch: 17, loss: 64.8628\n",
      "epoch: 18, loss: 58.8344\n",
      "epoch: 19, loss: 42.2226\n",
      "epoch: 20, loss: 33.2559\n",
      "epoch: 21, loss: 47.0197\n",
      "epoch: 22, loss: 32.6064\n",
      "epoch: 23, loss: 32.8828\n",
      "epoch: 24, loss: 43.3440\n",
      "epoch: 25, loss: 27.1222\n",
      "epoch: 26, loss: 17.5141\n",
      "epoch: 27, loss: 10.8909\n",
      "epoch: 28, loss: 7.8283\n",
      "epoch: 29, loss: 5.8629\n",
      "epoch: 30, loss: 5.0388\n",
      "epoch: 31, loss: 4.4577\n",
      "epoch: 32, loss: 3.9687\n",
      "epoch: 33, loss: 3.4488\n",
      "epoch: 34, loss: 2.9562\n",
      "epoch: 35, loss: 2.6984\n",
      "epoch: 36, loss: 2.4928\n",
      "epoch: 37, loss: 2.2985\n",
      "epoch: 38, loss: 2.0502\n",
      "epoch: 39, loss: 1.5529\n",
      "epoch: 40, loss: 1.2642\n",
      "epoch: 41, loss: 1.1223\n",
      "epoch: 42, loss: 1.0300\n",
      "epoch: 43, loss: 0.9496\n",
      "epoch: 44, loss: 0.8797\n",
      "epoch: 45, loss: 0.8166\n",
      "epoch: 46, loss: 0.7609\n",
      "epoch: 47, loss: 0.7093\n",
      "epoch: 48, loss: 0.6638\n",
      "epoch: 49, loss: 0.6205\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "rnn = RNN(len(text_vocab), 100, 30, len(label_vocab))\n",
    "rnn.to(device)\n",
    "optimizer = optim.SGD(rnn.parameters(), lr = 0.1)\n",
    "\n",
    "for epoch in range(50):\n",
    "    sumloss = 0.0\n",
    "    # In an environment with sufficient computing resources, it is better to use all the data.\n",
    "    # （計算資源が十分ある環境では，全てのデータを使う方が良い）\n",
    "    #for data in trainloader:  # Using all batches\n",
    "    for data in islice(trainloader, 250): # Using only 250 batches\n",
    "        x = data[0].to(device)\n",
    "        y = data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        a = rnn(x)\n",
    "        loss = F.cross_entropy(a, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sumloss += loss.item()\n",
    "    print('epoch: {}, loss: {:.4f}'.format(epoch, sumloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CmQFOsDNTZV3",
    "outputId": "f6d8df93-a39f-400c-aaa6-940d25662af0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5240825688073395\n"
     ]
    }
   ],
   "source": [
    "testloader.sort = False\n",
    "testloader.sort_within_batch = False\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        x = data[0].to(device)\n",
    "        y = data[1].to(device)\n",
    "        a = rnn(x)\n",
    "        pred_y = torch.argmax(a, dim=1)\n",
    "        correct += (pred_y == y).sum().item()\n",
    "        total += pred_y.size(0)\n",
    "\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "yf9AxkjhTZV3"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-90TCI21TZV4",
    "outputId": "eeb495c2-b8e6-4058-c6e8-137db41820cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos> it 's a charming and often affecting journey . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "true:1\n",
      "pred:1\n",
      "<bos> <unk> bleak and desperate <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "true:0\n",
      "pred:1\n",
      "<bos> allows us to hope that nolan is <unk> to <unk> a major career as a commercial yet inventive filmmaker . <eos>\n",
      "true:1\n",
      "pred:1\n",
      "<bos> the acting , costumes , music , cinematography and sound are all astounding given the production 's <unk> locales . <eos>\n",
      "true:1\n",
      "pred:1\n"
     ]
    }
   ],
   "source": [
    "data = dataiter.__next__()\n",
    "x = data[0].to(device)\n",
    "y = data[1].to(device)\n",
    "a = rnn(x)\n",
    "pred_y = torch.argmax(a, dim=1)\n",
    "for x_i, y_i, pred_y_i in zip(x, y, pred_y):\n",
    "    print(' '.join(text_vocab.lookup_tokens(list(x_i))))\n",
    "    print('true:' + label_vocab.lookup_token(y_i))\n",
    "    print('pred:' + label_vocab.lookup_token(pred_y_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
