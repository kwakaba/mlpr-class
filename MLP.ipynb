{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not execute this cell when you use example dataset.\n",
    "# （サンプルデータを使う場合は，このセルを実行しないこと）\n",
    "\n",
    "# If you want to use your own dataset, prepare a csv file as \"data.csv\" in the following format\n",
    "# （自分で用意したデータセットを使う場合は，データを以下のような形式のcsvファイルを「data.csv」として用意する）\n",
    "# sepal length (cm),sepal width (cm),petal length (cm),petal width (cm),class\n",
    "# 5.1,3.5,1.4,0.2,Iris-setosa\n",
    "# 4.9,3.0,1.4,0.2,Iris-setosa\n",
    "# 7.0,3.2,4.7,1.4,Iris-versicolor\n",
    "# 6.4,3.2,4.5,1.5,Iris-versicolor\n",
    "# 6.3,3.3,6.0,2.5,Iris-virginica\n",
    "# 5.8,2.7,5.1,1.9,Iris-virginica\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data.csv\", header=0)\n",
    "\n",
    "# Extract column names using the first row of a CSV file as a header.\n",
    "# （CSVファイルの最初の行をヘッダとして，列の名前を抽出する）\n",
    "# Set the rightmost column in the CSV file as the class.\n",
    "# （CSVファイルで一番右の列をクラスとする）\n",
    "target_column = df.columns.values.tolist()[-1]\n",
    "# Convert class name into ID numbers of 0, 1, 2, ...\n",
    "# （クラスの文字列を0, 1, 2, ...のID番号に変換する）\n",
    "target2id = dict((c, i) for i, c in enumerate(set(df[target_column].values.tolist())))\n",
    "\n",
    "data = {}\n",
    "data['feature_names'] = df.columns.values.tolist()[:-1]\n",
    "data['target_names'] = list([c for c, i in sorted(target2id.items(), key=lambda x: x[1])])\n",
    "data['target'] = np.array([target2id[c] for c in df[target_column].values.tolist()])\n",
    "data['data'] = np.array(df[data['feature_names']].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['data'][48:53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'][48:53]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class indicates iris species: class 0 is `'setosa'`, class 1 is `'versicolor'`, and class 2 is `'virginica'`.\n",
    "（クラス0が `'setosa'`, クラス1が `'versicolor'`, クラス2が `'virginica'` というアヤメの種類）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(data['data'], dtype=torch.float)\n",
    "y = torch.tensor(data['target'], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, xdim, hdim, ydim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(xdim, hdim)\n",
    "        self.linear2 = nn.Linear(hdim, ydim)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        a1 = self.linear1(X)\n",
    "        z1 = F.relu(a1)\n",
    "        a2 = self.linear2(z1)\n",
    "        return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(4, 2, 3)\n",
    "optimizer = optim.SGD(mlp.parameters(), lr = 0.1)\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    a = mlp(X)\n",
    "    loss = F.cross_entropy(a, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mlp(X)\n",
    "pred_proba = F.softmax(a, dim=1)\n",
    "pred_y = torch.argmax(pred_proba, dim=1)\n",
    "print(pred_y)\n",
    "print(pred_y == y)\n",
    "accuracy = (pred_y == y).sum() / float(len(pred_y))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = train_test_split(np.arange(len(X)), test_size=0.3, random_state=42)\n",
    "train_X = torch.tensor(data['data'][train_idx], dtype=torch.float)\n",
    "train_y = torch.tensor(data['target'][train_idx], dtype=torch.long)\n",
    "test_X = torch.tensor(data['data'][test_idx], dtype=torch.float)\n",
    "test_y = torch.tensor(data['target'][test_idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(train_X), len(train_y))\n",
    "print(len(test_X), len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp = MLP(4, 3, 3)\n",
    "optimizer = optim.SGD(mlp.parameters(), lr = 0.1)\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    a = mlp(train_X)\n",
    "    loss = F.cross_entropy(a, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mlp(test_X)\n",
    "pred_proba = F.softmax(a, dim=1)\n",
    "pred_y = torch.argmax(pred_proba, dim=1)\n",
    "print(pred_y)\n",
    "print(pred_y == test_y)\n",
    "accuracy = (pred_y == test_y).sum() / float(len(pred_y))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y.data, pred_y.data, target_names=data['target_names']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
